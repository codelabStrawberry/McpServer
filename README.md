# ollama-rag-mcp

Ollama + ChromaDB + FastAPI ê¸°ë°˜ **MCP(Model Context Protocol) RAG ì„œë²„** ì˜ˆì œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

ë¡œì»¬ LLM(Ollama)ì„ ì‚¬ìš©í•´ **Chat / RAG ê²€ìƒ‰ / ë¬¸ì„œ ì¶”ê°€**ë¥¼ MCP Tool í˜•íƒœì˜ APIë¡œ ì œê³µí•©ë‹ˆë‹¤.

---

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
MCPSERVER/
â”œâ”€ data/
â”‚ â””â”€ docs/
â”‚ â””â”€ chroma_data1.txt # ì˜ˆì œ RAG ë¬¸ì„œ
â”‚
â”œâ”€ mcp_server/
â”‚ â”œâ”€ api/
â”‚ â”‚ â”œâ”€ routes/
â”‚ â”‚ â”‚ â”œâ”€ chat.py # /mcp/tools/chat
â”‚ â”‚ â”‚ â”œâ”€ rag.py # /mcp/tools/rag_chat
â”‚ â”‚ â”‚ â””â”€ docs.py # /mcp/tools/add_doc, add_doc2
â”‚ â”‚ â”œâ”€ init.py
â”‚ â”‚ â”œâ”€ app.py # FastAPI app + lifespan
â”‚ â”‚ â””â”€ schemas.py # Pydantic request models
â”‚ â”‚
â”‚ â”œâ”€ chroma_db.py # ChromaDB client + ê²€ìƒ‰/ì €ì¥ ë¡œì§
â”‚ â”œâ”€ ollama.py # Ollama API wrapper (chat / embedding)
â”‚ â”œâ”€ ollama_client.py # AsyncClient ì „ì—­ ê´€ë¦¬
â”‚ â”œâ”€ rag.py # RAG prompt êµ¬ì„± ë¡œì§
â”‚ â”œâ”€ ingest.py # ë¬¸ì„œ ingest ìœ í‹¸ (ì„ íƒ)
â”‚ â”œâ”€ main.py # uvicorn entrypoint
â”‚ â”‚
â”‚ â”œâ”€ Dockerfile
â”‚ â”œâ”€ Dockerfile_Debug
â”‚ â”œâ”€ entrypoint.sh # ëª¨ë¸ pull + ì„œë²„ ì‹¤í–‰
â”‚ â”œâ”€ entrypoint_debug.sh
â”‚ â””â”€ requirements.txt
â”‚
â”œâ”€ .env
â”œâ”€ .env_sample
â”œâ”€ docker-compose.yml
â”œâ”€ docker-compose_Debug.yml
â””â”€ README.md
```

---

---

## âš™ï¸ í™˜ê²½ ë³€ìˆ˜ (.env)

```env
# -----------------------
# Ollama
# -----------------------
OLLAMA_BASE_URL=http://ollama:11434

# Chat ëª¨ë¸
OLLAMA_CHAT_MODEL=gemma3:1b

# Embedding ëª¨ë¸ (âš ï¸ ë°˜ë“œì‹œ embedding ì „ìš© ëª¨ë¸)
OLLAMA_EMBED_MODEL=nomic-embed-text

# -----------------------
# ChromaDB
# -----------------------
CHROMA_HOST=chroma
CHROMA_PORT=8000
CHROMA_COLLECTION=rag_docs

```

---

## ğŸš€ ì‹¤í–‰ ìˆœì„œ

### 1ï¸âƒ£ Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰

```bash
docker-compose up --build -d
docker compose build --no-cache
docker-compose up -d
```

Docker ìƒì„± í›„ `Dockerfile`ì—ì„œ `entrypoint.sh`ë¥¼ í˜¸ì¶œí•˜ì—¬ ì•„ë˜ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ pull í•©ë‹ˆë‹¤.

- `gemma3:1b`
- `nomic-embed-text`

ì„¤ì¹˜ ì—¬ë¶€ëŠ” ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.

docker-compose stop
stop í–ˆìœ¼ë©´ : docker-compose up -d

docker-compose down

```bash
docker logs ollama
```

ì»¨í…Œì´ë„ˆ ì¬ì‹¤í–‰ ì‹œ:

```bash
docker compose up -d
```

---

### 2ï¸âƒ£ Ollama ëª¨ë¸ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ (ì„ íƒ)

#### ê¸°ë³¸ LLM ëª¨ë¸

```bash
docker exec -it ollama ollama pull gemma3:1b
```

#### Embedding ëª¨ë¸ (RAG ë¬¸ì„œìš©)

```bash
docker exec -it ollama ollama pull nomic-embed-text
```

---

## ğŸ³ Docker ë””ë²„ê¹… ëª…ë ¹ì–´

```bash
docker compose build
docker compose up -d
docker compose up --build -d
docker compose build --no-cache
```

---

## ğŸ§ª API í…ŒìŠ¤íŠ¸ (Windows CMD ê¸°ì¤€)

> âš ï¸ **Windows CMDì—ì„œëŠ” ë°˜ë“œì‹œ í•œ ì¤„ JSON + ì´ì¤‘ ë”°ì˜´í‘œ escape ì‚¬ìš©**

---

### ğŸ’¬ Chat (LLM ë‹¨ë…)

---

### ğŸ“¥ ë¬¸ì„œ ì¶”ê°€ (RAG ì €ì¥)

```cmd
curl -X POST http://localhost:3333/mcp/tools/add_doc -H "Content-Type: application/json; charset=utf-8" -d "{\"id\":\"doc-001\",\"text\":\"MCP ì„œë²„ëŠ” LLMê³¼ ì™¸ë¶€ ë„êµ¬ë¥¼ ì—°ê²°í•˜ëŠ” ì¤‘ê°„ ê³„ì¸µ ì„œë²„ì´ë‹¤.\"}"
```

```cmd
curl -X POST http://localhost:3333/mcp/tools/add_doc2 -H "Content-Type: application/json; charset=utf-8" -d "{\"id\":\"doc-002\",\"text\":\"RAGëŠ” ê²€ìƒ‰ ê¸°ë°˜ìœ¼ë¡œ LLMì˜ í™˜ê°ì„ ì¤„ì´ëŠ” êµ¬ì¡°ì´ë‹¤.\"}"
```

---

### ğŸ” RAG ì§ˆì˜ (ê²€ìƒ‰ + LLM)

```cmd
curl -X POST http://localhost:3333/mcp/tools/rag_chat -H "Content-Type: application/json; charset=utf-8" -d "{\"question\":\"MCP ì„œë²„ êµ¬ì¡°ë¥¼ RAG ê¸°ì¤€ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜\"}"
```

---

## ğŸ§  ë‚´ë¶€ ë™ì‘ íë¦„

```
Client (curl / MCP)
  â””â”€ FastAPI (/mcp/tools/*)
       â”œâ”€ chat            â†’ Ollama LLM ì‘ë‹µ
       â”œâ”€ add_doc         â†’ Embedding â†’ ChromaDB ì €ì¥
       â””â”€ rag_chat
            â”œâ”€ Embedding (nomic-embed-text)
            â”œâ”€ ChromaDB ê²€ìƒ‰
            â””â”€ Ollama LLM ì‘ë‹µ


```

## ğŸ§   redis ì„¤ì¹˜

docker run -d --name redis7 -p 6379:6379 redis:7

# Docker / Ollama / MySQL ìš´ì˜ ë° ì •ë¦¬ ëª…ë ¹ ëª¨ìŒ

ì´ ë¬¸ì„œëŠ” MySQL ì»¨í…Œì´ë„ˆ ì‹¤í–‰, Ollama Host/Container ì œì–´,
Chroma ê°•ì œ ì¢…ë£Œ, Docker ì „ì²´ ì •ë¦¬ ë° í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰ ëª…ë ¹ì„
í•˜ë‚˜ì˜ Markdown íŒŒì¼ë¡œ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤.

---

## ğŸ§  MySQL ì„¤ì¹˜ (Docker)

docker run -d \
  --name mysql8 \
  -p 3306:3306 \
  -e MYSQL_ROOT_PASSWORD=1234 \
  -e MYSQL_DATABASE=board_db \
  -e MYSQL_USER=user \
  -e MYSQL_PASSWORD=pass \
  -v mysql8-data:/var/lib/mysql \
  --restart unless-stopped \
  mysql:8.0

---

## ğŸ§  Ollama Host ì„œë¹„ìŠ¤ ì¤‘ì§€ (ì¤‘ìš”)

Hostì— ì„¤ì¹˜ëœ Ollama ì„œë¹„ìŠ¤ëŠ” Docker Ollamaì™€ ì¶©ëŒí•˜ë¯€ë¡œ
ë°˜ë“œì‹œ ì¤‘ì§€ ë° ë¹„í™œì„±í™”í•´ì•¼ í•©ë‹ˆë‹¤.

sudo systemctl stop ollama
sudo systemctl disable ollama

í¬íŠ¸ í™•ì¸ (ì¶œë ¥ ì—†ì–´ì•¼ ì •ìƒ):

ss -lntp | grep 11434

---

## Docker Compose ì¬ì‹œì‘

docker compose down -v
docker compose up -d --build

---

## ğŸ§  Ollama / Chroma ê°•ì œ ì¤‘ì§€ (PID ê¸°ì¤€)

ì»¨í…Œì´ë„ˆ PID í™•ì¸:

docker inspect ollama --format '{{.State.Pid}}'
docker inspect chroma --format '{{.State.Pid}}'

PIDê°€ ë‚¨ì•„ ìˆëŠ” ê²½ìš° ê°•ì œ ì¢…ë£Œ:

sudo kill -9 <PID>

ì»¨í…Œì´ë„ˆ ê°•ì œ ì œê±°:

docker rm -f ollama chroma

---

## ì»¨í…Œì´ë„ˆ ìƒíƒœ ë° ë¡œê·¸ í™•ì¸

docker ps

docker logs ollama --tail 20
docker logs chroma --tail 20
docker logs mcp-server --tail 30

---

## Docker ì „ì²´ ì»¨í…Œì´ë„ˆ ì¤‘ì§€ / ì œê±°

ëª¨ë“  ì»¨í…Œì´ë„ˆ ì¤‘ì§€:

docker stop $(docker ps -aq)

ëª¨ë“  ì»¨í…Œì´ë„ˆ ì œê±°:

docker rm $(docker ps -aq)

ëª¨ë“  ì´ë¯¸ì§€ ì œê±°:

docker rmi -f $(docker images -aq)

íŠ¹ì • ì»¨í…Œì´ë„ˆ ì¤‘ì§€:

sudo docker stop mcp-server ollama chroma

---

## Docker íŒ¨í‚¤ì§€ ì™„ì „ ì œê±° (Ubuntu)

### 1ï¸âƒ£ Docker ê´€ë ¨ íŒ¨í‚¤ì§€ ì œê±°

sudo apt-get remove --purge -y \
  docker-ce \
  docker-ce-cli \
  docker-buildx-plugin \
  docker-compose-plugin \
  docker-ce-rootless-extras

sudo apt-get remove --purge -y \
  python3-compose \
  python3-docker \
  python3-dockerpty

sudo apt autoremove -y

---

## Ollama ì´ë¯¸ì§€ ì§ì ‘ ì‹¤í–‰ (ë””ë²„ê¹…ìš©)

DNS ì§€ì • + bash ì§„ì…:

docker run -it --rm \
  --dns=8.8.8.8 \
  --entrypoint /bin/bash \
  ollama/ollama:latest

ë³¼ë¥¨ í¬í•¨ ì‹¤í–‰:

docker run -it --rm \
  --dns=8.8.8.8 \
  -v ollama:/root/.ollama \
  --entrypoint /bin/bash \
  ollama/ollama:latest

---

## ì°¸ê³ 

- Host Ollama + Docker Ollama ë™ì‹œ ì‹¤í–‰ âŒ
- 11434 í¬íŠ¸ ì¶©ëŒ ì‹œ GPU/ì„œë²„ ëª¨ë‘ ì •ìƒ ë™ì‘ ì•ˆ í•¨
- ë¬¸ì œê°€ ìƒê¸°ë©´ ì»¨í…Œì´ë„ˆ â†’ ì´ë¯¸ì§€ â†’ Docker ìˆœìœ¼ë¡œ ì •ë¦¬í•˜ëŠ” ê²ƒì´ ê°€ì¥ í™•ì‹¤í•¨


# ì»¨í…Œì´ë„ˆ ì•ˆì—ì„œ
/usr/bin/ollama serve &
/usr/bin/ollama pull gemma3:1b
/usr/bin/ollama pull nomic-embed-text
/usr/bin/ollama list


# 1ï¸âƒ£ Ollama ì„œë²„ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
/usr/bin/ollama serve &

# 2ï¸âƒ£ gemma3:1b ëª¨ë¸ ì„¤ì¹˜
/usr/bin/ollama pull gemma3:1b

# 3ï¸âƒ£ nomic-embed-text ëª¨ë¸ ì„¤ì¹˜
/usr/bin/ollama pull nomic-embed-text

# 4ï¸âƒ£ ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸
/usr/bin/ollama list

---

---

## ğŸ³ Docker ë””ë²„ê¹… ëª…ë ¹ì–´

---

chmod +x ollama_install.sh

./ollama_install.sh

sudo ./ollama_install.sh
---

---

## ğŸ³ ì»¨í…Œì´ë„ˆ ì•ˆ or ì™¸ë¶€ì—ì„œ ëª¨ë¸ pull

```bash
<ìƒì„±>
docker exec -it ollama /usr/bin/ollama pull gemma3:1b
docker exec -it ollama /usr/bin/ollama pull nomic-embed-text

<ì œê±°>
docker exec -it ollama /usr/bin/ollama rm gemma3:1b
docker exec -it ollama /usr/bin/ollama rm nomic-embed-text

docker exec -it ollama /usr/bin/ollama list

<ìœˆë„ìš°>
MSYS_NO_PATHCONV=1 docker exec -it ollama /usr/bin/ollama list

```

## âŒ docker-compose-plugin í•„ìš”í•œ ê²½ìš° (ì•„ì§ ì´ˆê¸° ì„œë²„)

```bash
docker: command not found
docker: Cannot connect to the Docker daemon
docker compose: command not found

sudo apt update
sudo apt install docker docker-compose-plugin
```


# Ollama Docker GPU ì„¤ì • ê°€ì´ë“œ (Ubuntu + NVIDIA)

ì´ ë¬¸ì„œëŠ” Docker í™˜ê²½ì—ì„œ Ollama ì»¨í…Œì´ë„ˆê°€
NVIDIA GPUë¥¼ ì •ìƒì ìœ¼ë¡œ ì¸ì‹í•˜ë„ë¡ ì„¤ì •í•˜ëŠ” ì „ì²´ ì ˆì°¨ë¥¼
í•˜ë‚˜ì˜ Markdown íŒŒì¼ë¡œ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤.

---

## ì‚¬ì „ ì¡°ê±´

- Ubuntu
- NVIDIA GPU
- NVIDIA Driver ì„¤ì¹˜ ì™„ë£Œ
- Docker / Docker Compose ì„¤ì¹˜ ì™„ë£Œ
- í˜¸ìŠ¤íŠ¸ì—ì„œ nvidia-smi ì •ìƒ ë™ì‘

nvidia-smi

---

## GPUê°€ ì»¨í…Œì´ë„ˆì— ì „ë‹¬ë˜ì—ˆëŠ”ì§€ í™•ì¸

docker inspect ollama --format='{{.HostConfig.DeviceRequests}}'

ì •ìƒ ì¶œë ¥ ì˜ˆì‹œ:
[{gpu 0 [[gpu]] []}]

ë¹„ì–´ ìˆìœ¼ë©´ GPUê°€ ì»¨í…Œì´ë„ˆì— ì „ë‹¬ë˜ì§€ ì•Šì€ ìƒíƒœì…ë‹ˆë‹¤.

---

## ë¬¸ì œ ì›ì¸

DockerëŠ” ê¸°ë³¸ì ìœ¼ë¡œ GPUë¥¼ ì¸ì‹í•˜ì§€ ëª»í•©ë‹ˆë‹¤.
ë”°ë¼ì„œ NVIDIA Container Toolkit ì„¤ì¹˜ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.

---

## NVIDIA Container Toolkit ì„¤ì¹˜ ì ˆì°¨

ì•„ë˜ ìˆœì„œë¥¼ ê·¸ëŒ€ë¡œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

1. NVIDIA GPG í‚¤ ë“±ë¡

curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey \
| sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

2. NVIDIA ì €ì¥ì†Œ ì¶”ê°€

curl -fsSL https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list \
| sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' \
| sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

3. íŒ¨í‚¤ì§€ ëª©ë¡ ê°±ì‹ 

sudo apt-get update

4. NVIDIA Container Toolkit ì„¤ì¹˜

sudo apt-get install -y nvidia-container-toolkit

5. Docker ëŸ°íƒ€ì„ ì„¤ì • (ì¤‘ìš”)

sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker

â€» Docker ì¬ì‹œì‘ì„ í•˜ì§€ ì•Šìœ¼ë©´ 100% ì‹¤íŒ¨í•©ë‹ˆë‹¤.

---

## ì„¤ì¹˜ í™•ì¸

docker info | grep -i nvidia

ì •ìƒ ì¶œë ¥:
Runtimes: nvidia runc

---

## GPU í…ŒìŠ¤íŠ¸

docker run --rm --gpus all nvidia/cuda:12.2.0-base-ubuntu22.04 nvidia-smi

---

## Ollama ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘

docker compose down -v
docker compose up -d --build

---

## ìµœì¢… í™•ì¸

docker inspect ollama --format='{{.HostConfig.DeviceRequests}}'

ì •ìƒ ì¶œë ¥ì´ ë‚˜ì˜¤ë©´ GPU ì„¤ì • ì™„ë£Œì…ë‹ˆë‹¤.
