# ollama-rag-mcp

Ollama + ChromaDB + FastAPI ê¸°ë°˜ **MCP(Model Context Protocol) RAG ì„œë²„** ì˜ˆì œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

ë¡œì»¬ LLM(Ollama)ì„ ì‚¬ìš©í•´ **Chat / RAG ê²€ìƒ‰ / ë¬¸ì„œ ì¶”ê°€**ë¥¼ MCP Tool í˜•íƒœì˜ APIë¡œ ì œê³µí•©ë‹ˆë‹¤.

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ollama-rag-mcp/
â”œâ”€ docker-compose.yml
â”œâ”€ .env
â”œâ”€ mcp_server/
â”‚  â”œâ”€ Dockerfile
â”‚  â”œâ”€ requirements.txt
â”‚  â”œâ”€ main.py        # FastAPI MCP ì„œë²„
â”‚  â”œâ”€ rag.py         # RAG ë¡œì§
â”‚  â”œâ”€ chroma.py      # ChromaDB client
â”‚  â””â”€ ollama.py      # Ollama í˜¸ì¶œ
â””â”€ data/
   â””â”€ docs/          # RAG ë¬¸ì„œ ì €ì¥ ë””ë ‰í† ë¦¬
```

---

## âš™ï¸ í™˜ê²½ ë³€ìˆ˜ (.env)

```env
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=gemma3:1b

CHROMA_HOST=chroma
CHROMA_PORT=8000
CHROMA_COLLECTION=rag_docs
```

---

## ğŸš€ ì‹¤í–‰ ìˆœì„œ

### 1ï¸âƒ£ Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰

```bash
docker compose up -d
```

---

### 2ï¸âƒ£ Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

#### ê¸°ë³¸ LLM ëª¨ë¸

```bash
docker exec -it ollama ollama pull gemma3:1b
```

#### Embedding ëª¨ë¸ (RAG ë¬¸ì„œìš©)

```bash
docker exec -it ollama ollama pull nomic-embed-text
```

---

## ğŸ³ Docker ë””ë²„ê¹… ëª…ë ¹ì–´

```bash
docker-compose build
docker-compose up -d
docker-compose up --build -d
docker compose build --no-cache
```

---

## ğŸ§ª API í…ŒìŠ¤íŠ¸ (Windows CMD ê¸°ì¤€)

> âš ï¸ **Windows CMDì—ì„œëŠ” ë°˜ë“œì‹œ í•œ ì¤„ JSON + ì´ì¤‘ ë”°ì˜´í‘œ escape ì‚¬ìš©**

---

### ğŸ’¬ Chat (LLM ë‹¨ë…)

```cmd
curl -X POST http://localhost:3333/mcp/tools/chat -H "Content-Type: application/json; charset=utf-8" -d "{\"prompt\":\"MCP ì„œë²„ê°€ ë¬´ì—‡ì¸ì§€ ì„¤ëª…í•´ì¤˜\"}"
```

---

### ğŸ“¥ ë¬¸ì„œ ì¶”ê°€ (RAG ì €ì¥)

```cmd
curl -X POST http://localhost:3333/mcp/tools/add_doc -H "Content-Type: application/json; charset=utf-8" -d "{\"id\":\"doc-001\",\"text\":\"MCP ì„œë²„ëŠ” LLMê³¼ ì™¸ë¶€ ë„êµ¬ë¥¼ ì—°ê²°í•˜ëŠ” ì¤‘ê°„ ê³„ì¸µ ì„œë²„ì´ë‹¤.\"}"
```

```cmd
curl -X POST http://localhost:3333/mcp/tools/add_doc2 -H "Content-Type: application/json; charset=utf-8" -d "{\"id\":\"doc-002\",\"text\":\"RAGëŠ” ê²€ìƒ‰ ê¸°ë°˜ìœ¼ë¡œ LLMì˜ í™˜ê°ì„ ì¤„ì´ëŠ” êµ¬ì¡°ì´ë‹¤.\"}"
```

---

### ğŸ” RAG ì§ˆì˜ (ê²€ìƒ‰ + LLM)

```cmd
curl -X POST http://localhost:3333/mcp/tools/rag_chat -H "Content-Type: application/json; charset=utf-8" -d "{\"question\":\"MCP ì„œë²„ êµ¬ì¡°ë¥¼ RAG ê¸°ì¤€ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜\"}"
```

---

## ğŸ§  ë‚´ë¶€ ë™ì‘ íë¦„

```
Client (curl / MCP)
  â””â”€ FastAPI (/mcp/tools/*)
       â”œâ”€ ollama_chat      â†’ Ollama LLM ì‘ë‹µ
       â”œâ”€ add_doc          â†’ Embedding â†’ ChromaDB ì €ì¥
       â””â”€ rag_chat
            â”œâ”€ Embedding (nomic-embed-text)
            â”œâ”€ ChromaDB ê²€ìƒ‰
            â””â”€ Ollama LLM ì‘ë‹µ
```

---

## âœ… íŠ¹ì§•

- Docker ê¸°ë°˜ ë¡œì»¬ LLM (Ollama)
- ChromaDB ë²¡í„° ê²€ìƒ‰
- FastAPI MCP Tool êµ¬ì¡°
- Async ê¸°ë°˜ RAG íŒŒì´í”„ë¼ì¸
- Windows / Linux ëª¨ë‘ ì‚¬ìš© ê°€ëŠ¥

---

## ğŸ“Œ ì£¼ì˜ ì‚¬í•­

- Ollama embedding APIëŠ” **ë‹¨ì¼ í…ìŠ¤íŠ¸ ê¸°ì¤€**ìœ¼ë¡œ ì‚¬ìš©
- ëª¨ë“  async í•¨ìˆ˜ëŠ” ë°˜ë“œì‹œ `await` í•„ìš”
- Windows CMDëŠ” JSON escape í•„ìˆ˜

---

## ğŸ“œ License

MIT
