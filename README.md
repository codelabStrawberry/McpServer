# ollama-rag-mcp

Ollama + ChromaDB + FastAPI ê¸°ë°˜ **MCP(Model Context Protocol) RAG ì„œë²„** ì˜ˆì œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

ë¡œì»¬ LLM(Ollama)ì„ ì‚¬ìš©í•´ **Chat / RAG ê²€ìƒ‰ / ë¬¸ì„œ ì¶”ê°€**ë¥¼ MCP Tool í˜•íƒœì˜ APIë¡œ ì œê³µí•©ë‹ˆë‹¤.

---

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
MCPSERVER/
â”œâ”€ data/
â”‚ â””â”€ docs/
â”‚ â””â”€ chroma_data1.txt # ì˜ˆì œ RAG ë¬¸ì„œ
â”‚
â”œâ”€ mcp_server/
â”‚ â”œâ”€ api/
â”‚ â”‚ â”œâ”€ routes/
â”‚ â”‚ â”‚ â”œâ”€ chat.py # /mcp/tools/chat
â”‚ â”‚ â”‚ â”œâ”€ rag.py # /mcp/tools/rag_chat
â”‚ â”‚ â”‚ â””â”€ docs.py # /mcp/tools/add_doc, add_doc2
â”‚ â”‚ â”œâ”€ init.py
â”‚ â”‚ â”œâ”€ app.py # FastAPI app + lifespan
â”‚ â”‚ â””â”€ schemas.py # Pydantic request models
â”‚ â”‚
â”‚ â”œâ”€ chroma_db.py # ChromaDB client + ê²€ìƒ‰/ì €ì¥ ë¡œì§
â”‚ â”œâ”€ ollama.py # Ollama API wrapper (chat / embedding)
â”‚ â”œâ”€ ollama_client.py # AsyncClient ì „ì—­ ê´€ë¦¬
â”‚ â”œâ”€ rag.py # RAG prompt êµ¬ì„± ë¡œì§
â”‚ â”œâ”€ ingest.py # ë¬¸ì„œ ingest ìœ í‹¸ (ì„ íƒ)
â”‚ â”œâ”€ main.py # uvicorn entrypoint
â”‚ â”‚
â”‚ â”œâ”€ Dockerfile
â”‚ â”œâ”€ Dockerfile_Debug
â”‚ â”œâ”€ entrypoint.sh # ëª¨ë¸ pull + ì„œë²„ ì‹¤í–‰
â”‚ â”œâ”€ entrypoint_debug.sh
â”‚ â””â”€ requirements.txt
â”‚
â”œâ”€ .env
â”œâ”€ .env_sample
â”œâ”€ docker-compose.yml
â”œâ”€ docker-compose_Debug.yml
â””â”€ README.md
```

---

---

## âš™ï¸ í™˜ê²½ ë³€ìˆ˜ (.env)

```env
# -----------------------
# Ollama
# -----------------------
OLLAMA_BASE_URL=http://ollama:11434

# Chat ëª¨ë¸
OLLAMA_CHAT_MODEL=gemma3:1b

# Embedding ëª¨ë¸ (âš ï¸ ë°˜ë“œì‹œ embedding ì „ìš© ëª¨ë¸)
OLLAMA_EMBED_MODEL=nomic-embed-text

# -----------------------
# ChromaDB
# -----------------------
CHROMA_HOST=chroma
CHROMA_PORT=8000
CHROMA_COLLECTION=rag_docs

```

---

## ğŸš€ ì‹¤í–‰ ìˆœì„œ

### 1ï¸âƒ£ Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰

```bash
docker-compose up --build -d
docker compose build --no-cache
docker-compose up -d
```

Docker ìƒì„± í›„ `Dockerfile`ì—ì„œ `entrypoint.sh`ë¥¼ í˜¸ì¶œí•˜ì—¬ ì•„ë˜ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ pull í•©ë‹ˆë‹¤.

- `gemma3:1b`
- `nomic-embed-text`

ì„¤ì¹˜ ì—¬ë¶€ëŠ” ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ í™•ì¸í•©ë‹ˆë‹¤.

docker-compose stop
stop í–ˆìœ¼ë©´ : docker-compose up -d

docker-compose down

```bash
docker logs ollama
```

ì»¨í…Œì´ë„ˆ ì¬ì‹¤í–‰ ì‹œ:

```bash
docker compose up -d
```

---

### 2ï¸âƒ£ Ollama ëª¨ë¸ ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ (ì„ íƒ)

#### ê¸°ë³¸ LLM ëª¨ë¸

```bash
docker exec -it ollama ollama pull gemma3:1b
```

#### Embedding ëª¨ë¸ (RAG ë¬¸ì„œìš©)

```bash
docker exec -it ollama ollama pull nomic-embed-text
```

---

## ğŸ³ Docker ë””ë²„ê¹… ëª…ë ¹ì–´

```bash
docker-compose build
docker-compose up -d
docker-compose up --build -d
docker compose build --no-cache
```

---

## ğŸ§ª API í…ŒìŠ¤íŠ¸ (Windows CMD ê¸°ì¤€)

> âš ï¸ **Windows CMDì—ì„œëŠ” ë°˜ë“œì‹œ í•œ ì¤„ JSON + ì´ì¤‘ ë”°ì˜´í‘œ escape ì‚¬ìš©**

---

### ğŸ’¬ Chat (LLM ë‹¨ë…)

---

### ğŸ“¥ ë¬¸ì„œ ì¶”ê°€ (RAG ì €ì¥)

```cmd
curl -X POST http://localhost:3333/mcp/tools/add_doc -H "Content-Type: application/json; charset=utf-8" -d "{\"id\":\"doc-001\",\"text\":\"MCP ì„œë²„ëŠ” LLMê³¼ ì™¸ë¶€ ë„êµ¬ë¥¼ ì—°ê²°í•˜ëŠ” ì¤‘ê°„ ê³„ì¸µ ì„œë²„ì´ë‹¤.\"}"
```

```cmd
curl -X POST http://localhost:3333/mcp/tools/add_doc2 -H "Content-Type: application/json; charset=utf-8" -d "{\"id\":\"doc-002\",\"text\":\"RAGëŠ” ê²€ìƒ‰ ê¸°ë°˜ìœ¼ë¡œ LLMì˜ í™˜ê°ì„ ì¤„ì´ëŠ” êµ¬ì¡°ì´ë‹¤.\"}"
```

---

### ğŸ” RAG ì§ˆì˜ (ê²€ìƒ‰ + LLM)

```cmd
curl -X POST http://localhost:3333/mcp/tools/rag_chat -H "Content-Type: application/json; charset=utf-8" -d "{\"question\":\"MCP ì„œë²„ êµ¬ì¡°ë¥¼ RAG ê¸°ì¤€ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜\"}"
```

---

## ğŸ§  ë‚´ë¶€ ë™ì‘ íë¦„

```
Client (curl / MCP)
  â””â”€ FastAPI (/mcp/tools/*)
       â”œâ”€ chat            â†’ Ollama LLM ì‘ë‹µ
       â”œâ”€ add_doc         â†’ Embedding â†’ ChromaDB ì €ì¥
       â””â”€ rag_chat
            â”œâ”€ Embedding (nomic-embed-text)
            â”œâ”€ ChromaDB ê²€ìƒ‰
            â””â”€ Ollama LLM ì‘ë‹µ


```

## ğŸ§   redis ì„¤ì¹˜

docker run -d --name redis7 -p 6379:6379 redis:7

## ğŸ§   ollama host ì¤‘ì§€
sudo systemctl stop ollama
sudo systemctl disable ollama
ss -lntp | grep 11434   # ì¶œë ¥ ì—†ì–´ì•¼ í•¨

docker compose down -v
docker compose up -d --build

## ğŸ§   ollama chroma ê°•ì œ ì¤‘ì§€
docker inspect ollama --format '{{.State.Pid}}'
docker inspect chroma --format '{{.State.Pid}}'

sudo kill -9 12345(PID)

docker rm -f ollama chroma


docker ps
docker logs ollama --tail 20
docker logs chroma --tail 20
docker logs mcp-server --tail 30


docker stop $(docker ps -aq)
docker rm $(docker ps -aq)

docker rmi -f $(docker images -aq)

sudo docker stop mcp-server ollama chroma

1ï¸âƒ£ Docker íŒ¨í‚¤ì§€ ì œê±°
sudo apt-get remove --purge -y docker-ce docker-ce-cli docker-buildx-plugin docker-compose-plugin docker-ce-rootless-extras
sudo apt-get remove --purge -y python3-compose python3-docker python3-dockerpty
sudo apt autoremove -y


docker run -it --rm --dns=8.8.8.8 --entrypoint /bin/bash ollama/ollama:latest

docker run -it --rm \
  --dns=8.8.8.8 \
  -v ollama:/root/.ollama \
  --entrypoint /bin/bash \
  ollama/ollama:latest

# ì»¨í…Œì´ë„ˆ ì•ˆì—ì„œ
/usr/bin/ollama serve &
/usr/bin/ollama pull gemma3:1b
/usr/bin/ollama pull nomic-embed-text
/usr/bin/ollama list


# 1ï¸âƒ£ Ollama ì„œë²„ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
/usr/bin/ollama serve &

# 2ï¸âƒ£ gemma3:1b ëª¨ë¸ ì„¤ì¹˜
/usr/bin/ollama pull gemma3:1b

# 3ï¸âƒ£ nomic-embed-text ëª¨ë¸ ì„¤ì¹˜
/usr/bin/ollama pull nomic-embed-text

# 4ï¸âƒ£ ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸
/usr/bin/ollama list

---

---

## ğŸ³ Docker ë””ë²„ê¹… ëª…ë ¹ì–´

---

chmod +x ollama_install.sh

./ollama_install.sh

sudo ./ollama_install.sh
---

---

## ğŸ³ ì»¨í…Œì´ë„ˆ ì•ˆ or ì™¸ë¶€ì—ì„œ ëª¨ë¸ pull

```bash
<ìƒì„±>
docker exec -it ollama /usr/bin/ollama pull gemma3:1b
docker exec -it ollama /usr/bin/ollama pull nomic-embed-text

<ì œê±°>
docker exec -it ollama /usr/bin/ollama rm gemma3:1b
docker exec -it ollama /usr/bin/ollama rm nomic-embed-text

docker exec -it ollama /usr/bin/ollama list

```