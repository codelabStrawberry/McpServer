#!/bin/sh
set -e

echo "▶ Waiting for Ollama..."
until curl -sf "$OLLAMA_BASE_URL/api/tags" > /dev/null; do
  sleep 2
done

echo "▶ Pull Ollama chat model: $OLLAMA_CHAT_MODEL"
ollama pull "$OLLAMA_CHAT_MODEL" || true

echo "▶ Pull Ollama embedding model: $OLLAMA_EMBED_MODEL"
ollama pull "$OLLAMA_EMBED_MODEL" || true

echo "▶ Start MCP Server"
exec uvicorn main:app --host 0.0.0.0 --port 3333


docker run -it --rm --dns=8.8.8.8 -p 11434:11434 --entrypoint /bin/bash ollama/ollama:latest
# 컨테이너 안에서
/usr/bin/ollama serve &
/usr/bin/ollama pull gemma3:1b
/usr/bin/ollama list